# 🔐 LLM-Based Code Generation and Vulnerability Analysis

This project explores the security of source code generated by large language models (LLMs). It combines automated code generation using OpenAI’s GPT-3.5 API with a trained machine learning–based vulnerability analyzer. Users can input prompts to generate code and receive real‑time feedback on whether the generated code is secure or vulnerable.

---

## 📖 Project Description

- **Code Generation Module** – Generates source code from natural‑language prompts with GPT‑3.5.  
- **Security Analysis Module** – Detects vulnerabilities in generated or user‑provided code via an ML ensemble trained on the NIST Juliet Suite.  
- **Flask REST API** – Orchestrates generation and analysis endpoints.  
- **React Frontend** – Web UI for prompt entry and result visualization.

---

## 🛠️ Installation Instructions

### Backend (Flask)

```bash
git clone https://github.com/GTU-CyberAI/LLMCode.git
cd LLMCode/src/backend

python -m venv venv
source venv/bin/activate        # Windows: venv\Scripts\activate
pip install -r requirements.txt

cp .env.example .env            # add your OpenAI key + model paths
python app.py                   # start backend
```


## Frontend (React)
```bash
cd ../../frontend
npm install
npm start
```

---

### ▶️ Usage Examples
## Generate Code
```bash
curl -X POST http://127.0.0.1:5000/api/generate-code \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Write a C function to reverse a string."}'
  ```

##  Analyze Existing Code

```bash
  curl -X POST http://127.0.0.1:5000/api/analyze-existing \
  -H "Content-Type: application/json" \
  -d '{"code": "char buf[10]; gets(buf);"}'
  ```

--- 


## 📁 Repository Structure
LLMCode/
├── src/
│   ├── backend/
│   │   ├── app.py            # Flask API
│   │   ├── trained_model_loader.py
│   │   ├── models/           # *.pkl / *.joblib files
│   │   └── utils/            # helpers
│   └── frontend/             # React app
├── requirements.txt          # backend deps
└── README.md
