# ğŸ” LLM-Based Code Generation and Vulnerability Analysis

This project explores the security of source code generated by large language models (LLMs). It combines automated code generation using OpenAIâ€™s GPT-3.5 API with a trained machine learningâ€“based vulnerability analyzer. Users can input prompts to generate code and receive realâ€‘time feedback on whether the generated code is secure or vulnerable.

---

## ğŸ“– Project Description

- **Code Generation Module** â€“ Generates source code from naturalâ€‘language prompts with GPTâ€‘3.5.  
- **Security Analysis Module** â€“ Detects vulnerabilities in generated or userâ€‘provided code via an ML ensemble trained on the NIST Juliet Suite.  
- **Flask REST API** â€“ Orchestrates generation and analysis endpoints.  
- **React Frontend** â€“ Web UI for prompt entry and result visualization.

---

## ğŸ› ï¸ Installation Instructions


### Prerequisites
- Python 3.8+
- Node.js 14+
- OpenAI API Key

### Environment setup
1. Create Environment file:
```bash
cp .env.example .env
```

2. Add your OpenAI API Key:
```bash
# Edit .env file and replace 'your_openai_api_key_here' with your actual key
nano .env
# OR
code .env
```

3. Get OpenAI API Key (if you don't have one):
- Go to OpenAI Platform
- Sign in or create account
- Click "Create new secret key"
- Copy the key and paste it in your .env file

4. Verify environment setup:
```bash
# Your .env should look like this:
OPENAI_API_KEY=sk-proj-xxxxxxxxxx...
FLASK_DEBUG=True
PORT=5000
MODEL_PATH=models/consistent_security_analyzer.pkl
LOG_LEVEL=INFO
```




### Backend (Flask)

```bash
git clone https://github.com/GTU-CyberAI/LLMCode.git
cd LLMCode/src/backend

python -m venv venv
source venv/bin/activate        # Windows: venv\Scripts\activate
pip install -r requirements.txt

cp .env.example .env            # add your OpenAI key + model paths
python app.py                   # start backend
```


## Frontend (React)
```bash
cd ../../frontend
npm install
npm start
```

---

## Testing 
### Running System Tests
To verify that all components are working clearly:

```bash
cd src/backend
source venv/bin/activate
python app.py
```

in a new terminal, run tests
```bash
cd tests
source venv/bin/activate
python test_system_health.py
```

### Test Coverage
- âœ… Backend Health Check â€“ Verifies Flask server is responding
- âœ… API Endpoints â€“ Tests /api/health, /api/model-info endpoints
- âœ… Code Analysis â€“ Validates security analysis functionality

### Expected output

ğŸ§ª LLMCode Sistem Testi
========================================
âœ… Backend Ã§alÄ±ÅŸÄ±yor
   Status: 200
   Response: {'status': 'healthy', ...}
========================================
ğŸ“¡ API Endpoint Testi:
âœ… Health Check: OK
âœ… Model Info: OK
========================================
ğŸ” Kod Analizi Testi:
âœ… Kod analizi Ã§alÄ±ÅŸÄ±yor
   Analiz tamamlandÄ±: True
âœ… TÃ¼m testler tamamlandÄ±!

---

## ğŸ› ï¸ Troubleshooting

| Issue                        | Fix                                                         |
|------------------------------|-------------------------------------------------------------|
| `ModuleNotFoundError`        | Activate **venv** & reinstall deps                          |
| Frontend cannot reach backend| Confirm Flask is running and **CORS** is enabled           |
| OpenAI API errors            | Verify `OPENAI_API_KEY` is set in **.env**                 |
| Modelâ€‘file load failure      | Ensure model artifacts exist in `src/backend/models/`       |

---

# ğŸ“‚ FILE_OVERVIEW.md  
_Key files and their purpose in **LLMCode**_

| Path | Purpose | Key Functions / Classes |
|------|---------|-------------------------|
| **src/backend/app.py** | Flask entryâ€‘point; exposes `/api/generate-code`, `/api/analyze-existing`, etc. | `create_app()`, `generate_code()`, `analyze_existing()` |
| **src/backend/trained_model_loader.py** | Loads the serialized ML ensemble and provides `predict_vulnerability()` helper. | `ModelLoader`, `predict_vulnerability()` |
| **src/backend/models/consisten_security_analyzer.pkl** | Trained model artifacts (`*.pkl`, `*.joblib`) loaded at runtime. | n/a â€“ binary model files |
| **src/frontend/** | React SPA for prompt input and result visualization; communicates with Flask via Axios. | `App.jsx`, `CodeInputForm.jsx`, `ResultCard.jsx` |
| **requirements.txt** | Exact Python packages & versions for backend; install with `pip install -r requirements.txt`. | n/a |
| **.env.example** | Template for environment variables (`OPENAI_API_KEY`, model path). Copy to `.env` and fill values. | n/a |
| **README.md** | Main documentation: intro, install guide, usage, troubleshooting, acknowledgements. | n/a |

---

## ğŸ¤ Acknowledgements
- **Course:** *CSE 473 - Network And Information Security*
- **Instructor:** *Dr. Ã–ÄŸr. Ãœyesi Salih Sarp.*
- **Team Members:** Arife Yurtseven Â· Ä°lker YÄ±lmaz