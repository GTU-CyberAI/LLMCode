# 🔐 LLM-Based Code Generation and Vulnerability Analysis

This project explores the security of source code generated by large language models (LLMs). It combines automated code generation using OpenAI’s GPT-3.5 API with a trained machine learning–based vulnerability analyzer. Users can input prompts to generate code and receive real‑time feedback on whether the generated code is secure or vulnerable.

---

## 📖 Project Description

- **Code Generation Module** – Generates source code from natural‑language prompts with GPT‑3.5.  
- **Security Analysis Module** – Detects vulnerabilities in generated or user‑provided code via an ML ensemble trained on the NIST Juliet Suite.  
- **Flask REST API** – Orchestrates generation and analysis endpoints.  
- **React Frontend** – Web UI for prompt entry and result visualization.

---

## 🛠️ Installation Instructions


### Prerequisites
- Python 3.8+
- Node.js 14+
- OpenAI API Key

### Environment setup
1. Create Environment file:
```bash
cp .env.example .env
```

2. Add your OpenAI API Key:
```bash
# Edit .env file and replace 'your_openai_api_key_here' with your actual key
nano .env
# OR
code .env
```

3. Get OpenAI API Key (if you don't have one):
- Go to OpenAI Platform
- Sign in or create account
- Click "Create new secret key"
- Copy the key and paste it in your .env file

4. Verify environment setup:
```bash
# Your .env should look like this:
OPENAI_API_KEY=sk-proj-xxxxxxxxxx...
FLASK_DEBUG=True
PORT=5000
MODEL_PATH=models/consistent_security_analyzer.pkl
LOG_LEVEL=INFO
```




### Backend (Flask)

```bash
git clone https://github.com/GTU-CyberAI/LLMCode.git
cd LLMCode/src/backend

python -m venv venv
source venv/bin/activate        # Windows: venv\Scripts\activate
pip install -r requirements.txt

cp .env.example .env            # add your OpenAI key + model paths
python app.py                   # start backend
```


## Frontend (React)
```bash
cd ../../frontend
npm install
npm start
```

---

## Testing 
### Running System Tests
To verify that all components are working clearly:

```bash
cd src/backend
source venv/bin/activate
python app.py
```

in a new terminal, run tests
```bash
cd tests
source venv/bin/activate
python test_system_health.py
```

### Test Coverage
- ✅ Backend Health Check – Verifies Flask server is responding
- ✅ API Endpoints – Tests /api/health, /api/model-info endpoints
- ✅ Code Analysis – Validates security analysis functionality

### Expected output

🧪 LLMCode Sistem Testi
========================================
✅ Backend çalışıyor
   Status: 200
   Response: {'status': 'healthy', ...}
========================================
📡 API Endpoint Testi:
✅ Health Check: OK
✅ Model Info: OK
========================================
🔍 Kod Analizi Testi:
✅ Kod analizi çalışıyor
   Analiz tamamlandı: True
✅ Tüm testler tamamlandı!

---

## 🛠️ Troubleshooting

| Issue                        | Fix                                                         |
|------------------------------|-------------------------------------------------------------|
| `ModuleNotFoundError`        | Activate **venv** & reinstall deps                          |
| Frontend cannot reach backend| Confirm Flask is running and **CORS** is enabled           |
| OpenAI API errors            | Verify `OPENAI_API_KEY` is set in **.env**                 |
| Model‑file load failure      | Ensure model artifacts exist in `src/backend/models/`       |

---

# 📂 FILE_OVERVIEW.md  
_Key files and their purpose in **LLMCode**_

| Path | Purpose | Key Functions / Classes |
|------|---------|-------------------------|
| **src/backend/app.py** | Flask entry‑point; exposes `/api/generate-code`, `/api/analyze-existing`, etc. | `create_app()`, `generate_code()`, `analyze_existing()` |
| **src/backend/trained_model_loader.py** | Loads the serialized ML ensemble and provides `predict_vulnerability()` helper. | `ModelLoader`, `predict_vulnerability()` |
| **src/backend/models/consisten_security_analyzer.pkl** | Trained model artifacts (`*.pkl`, `*.joblib`) loaded at runtime. | n/a – binary model files |
| **src/frontend/** | React SPA for prompt input and result visualization; communicates with Flask via Axios. | `App.jsx`, `CodeInputForm.jsx`, `ResultCard.jsx` |
| **requirements.txt** | Exact Python packages & versions for backend; install with `pip install -r requirements.txt`. | n/a |
| **.env.example** | Template for environment variables (`OPENAI_API_KEY`, model path). Copy to `.env` and fill values. | n/a |
| **README.md** | Main documentation: intro, install guide, usage, troubleshooting, acknowledgements. | n/a |

---

## 🤝 Acknowledgements
- **Course:** *CSE 473 - Network And Information Security*
- **Instructor:** *Dr. Öğr. Üyesi Salih Sarp.*
- **Team Members:** Arife Yurtseven · İlker Yılmaz